# Data Gathering

<!-- TODO: fix dashes (" n " to "m"), italicize quotes, turn “” into “” -->

In this chapter, I will show how to gather data to get to know about the activities, motivations and problems of our research participants.
You will gather information by listening to descriptions and explanations of our participants and by observing them working.
The resulting data will be text, photos and diagrams.

Contrary to a common misconception of user need research, your inquiry will not be (directly) about future ideas and design –
you are not going to ask “do you think that a \[gadget\] would help you?”. It is hard to reliably guess if something would be a
great thing to have in the future and the answer would tell you not much about the actual activities, motivations or problems
of the participant. Instead of dealing with ideas directly, you will find out about the *how* and *why* of our participant’s activities.
This will allow to evaluate your ideas (“do my ideas match what they consider essential?”) and to get inspiration for new ideas (“how can I support this motivation?”)

To make this work, see your participants as competent in what they do: they are experts in their fields and in their daily work. This is contrary to the idea that people “don’t get it” and need to be helped by designers and programmers. Instead of this, assume that the participants have a reason of doing their work the way they do it.

<!-- TODO: Show intertwinement with analysis and sensemaking

e.g. The gathering the data will be followed by analyzing it. However, it makes sense to intertwine the data gathering and data analysis: … TODO

-->

## Modes of data gathering

### Listening and asking questions

A common way to gather data is asking questions and listening to the participant’s answers. However, the use of questions and answers in user needfinding is unlike the questions and answers in questionnaires. Questionnaires often aimed for short, definitive answers which need to be selected from of a set of possibilities (“on a 4 point scale: how much do you agree with…”). In user needfinding instead, you aim for longer answers that are not from a determined set of possible answers. Thus, you are more likely to get rich descriptions, much like stories which retell the participant’s experiences. These stories tell you about the context of the user’s activities and the user’s motivations. To encourage giving such story like answers, you  often need to ask for descriptions of activities and the reasons for doing them.

> “Can you describe me how you decided to use this layout?”
>
> OR
>
> “You said that you need to look that color model up. Why?”

Asking questions and getting answers form a participant is a very versatile tool. It can be done without many resources. You are not tied to a specific place and you can talk about past events as well as future plans.

But because of this it can happen that you hardly focus on actual experiences and instead talk about abstract events. Observations are thus a good supplement to asking questions and listening, since observations are concerned with actual actions you can see happening at the very moment.

### Observe

What Participants describe is not always the ideal way to convey the information. Just like a picture can be worth a thousand words, it makes often sense to ask participants to show what they mean and to demonstrate how they work. It can also be easier compared to describing to.

When you observe, you will even notice things your participants would never consider mentioning: It may have get second nature for them which tools they use, how they apply these tools to their work and which problems they meet, so they won't mention it. But you can observe it. You can also gain information about the context, like means of communicating with co-workers or cues in the environment that point out problems—for example quick fixes on devices using tape and cardboard, or added instructions on devices and machines.

<!-- possibly show photo of quickfix here like the taped credit card machine: https://www.flickr.com/photos/31068346@N05/35836744434/in/dateposted-public/ -->

It is not needed to have observation as a separate step in the research process. It makes great sense to interweave it with asking questions and listening. Just ask for a demonstration instead of a description.

> Participant: “So I got this image and now I would try to get a suitable crop for that flyer”
> Researcher: “Can you show me how you do it?”

Think of yourself as an apprentice of the participant. The participant is the expert who can teach you some of their skills. This means that understanding the user by observing is not a passive process. Like an apprentice, you can and should ask questions.

> Ask about reasons: “You drew that object and changed it size, then you deleted it again… what was the reason behind this?
> Ask about things you notice in the environment: “Can you tell me what these markings are for?”

Teaching an apprentice is not a theoretical or artificially set up process: The tasks you observe should be tasks the participant is actually doing (and not something set up for you):

> Participant: “What should I do now?”
> You: “What would you do if I would not be here?”

Of course, they should be relevant to your interests as well:

> [continuing the conversation above] Participant: “I would either crop this bunch of images or I'd try to find a suitable font for the headlines in this document
> You: “If the tasks are equally relevant to you, I'd be more interested in watching you choosing the fonts”

Avoid positioning yourself as the expert in the participant’s domain by suggesting procedures and by telling the participant how and why something should be done. If the participant would just look up to you and your concept of how work should be done we would not get to know anything.

![observing the user’s work](images/ObservationDesign1.jpg)

### Co-Document in diagrams and lists

<!-- todo: Review with images -->

In co-documentation, the participant and you record the data together by drawing and writing. This can be as simple as asking the participant: *“Draw a simple floorplan of your office. Mark what is important to your work and write why”*.

Here are some examples of co-documentation results:

![timeline diagram. If the graph goes up, the mood gets better, if it goes down, the participant feels bad, borded or annoyed](images/U1_GoodBadTime_Diagramm.svg)

![social space map: The participant is in the center. They draw people (or whatever else they think matters) around them and write the nature of the connection on the arrows](images/diagram_people.svg)

![List with workflow steps](images/List_Task.png)

Having the documentation in front of you and the participant eases improving it directly while it is being created. You, the researcher, can refer to it to ask for elaboration (*“Is this the photocopying machine, that you said gets stuck so often?”*). The information provided in the answer should be added to the documentations. The participant can use the shared documentation to extend already documented things (*“One other thing I add is that I can get paper for the xerox here [writes comment on the paper]”*). Since researcher and participant need to understand the documentation is a check against unclear terms, references and also just sloppy writing. This makes the results often very accessible and useful.

> “The line here seems to indicate that you were very happy at the beginning of the project…” Participant: “Yes, I’m looking forward to doing it and there are so many ideas” You: “Can you write this in the diagram, so I can understand it later?” Participant: [Writes as comment in the diagram] Looking forward, Many Ideas: Good

Who does the recording—drawing and/or writing—depends on what is more practical and gives more interesting data. When researching workflows, *I* write the documentation as a researcher, since participants should be able to demonstrate their tasks directly which is hard when you need to switch between demonstrating and writing all the time. When the participants document a project on a timeline, *they* draw it directly and I only ask questions.

On way to ease the documenting for the participant is showing a simple example of what the result of a co-documentation can look like. It is helpful if the participant has no clear idea of what they should do. It can also reduce anxiety in drawing related tasks—some people assume they need to produce an artwork and showing that a rough sketch is fine.

<!-- Example -->

For some types of documentation, templates can be very useful: They give a basic structure and the participant can fill in the data. This is most useful for chart-like types of diagrams or for annotating a map. But even if you can't provide a template for the primary data, you can still prepare paper with an example, fields for the name, date and title and a blank space for the data. I also sometimes print a small example in a corner of the template.

![example template for mood-timeline-diagrams](images/GoodBadTime_Diagramm.svg)

The use of co documentation may be a less widespread method than interviews and observation. It plays well with both, though: You can co-document workflows combined with observing them and you can also go from an interview to co-documenting a specific aspect (*“That is interesting! I would like to remember it clarly later on, so I would like to write the steps down with you”*) or use a documentation to refer back to in an interview (*“You wrote… How does relate to…”*) and add further details to it.

Co-documenting via lists, diagrams and drawings may seem unusual in the beginning. But they produce very useful and graspable data by having the researcher and the participant work together. The participant’s active part in documenting and the possibility to see directly what is recorded can empower participants: They are not just passive sources but actively create data.

## Start the research session

### Explain the research project and methods

When you have found a participant, a place, a time and have your equipment ready, you can start with the actual research session.

My advice is simple: Be friendly. If you come to
their place (which is preferable, since you can observe the actual
context) be a nice guest; if they come to your place or you meet in some “neutral space” (which includes online conversations), be a nice host.

Greet the participant and thank for their time:

> Hello Lisa, great to meet you. I’m pleased that you could free some time for showing and telling me how you work.

You may sprinkle in a bit of smalltalk:

> Did you have a good start into the day?

Participants should at least roughly know what the research is
about. You don't need to reveal all your questions and topics,
 but the general topic should be described

> This research helps us to improve the workflow in the design process to design solutions for people who do graphic design.

Make clear that you are here to learn—and not an evaluator of the
quality of the participant’s work.

>…Therefore we'd like to get to know how you work. You are an expert in
> that field and we'd like to learn from you. This is not some kind of
> test—when I ask questions, there are no wrong answers.

Although you may have described the time frame and the method already
when recruiting the participant, tell again what you are going to do:

> We will have a conversation about your work and I'll be asking some questions. In addition, I’m interested in watching you when you do your work. The whole process will take about an hour.


The participant must know how you record data and who will see it. So
tell the Participant:


> I'd like to take notes, and, in addition, record audio—if that is
> OK with you. The audio recording helps me to focus on your work as I
> don’t need to concentrate as much on writing notes, if I have the
> recording as backup. Me and a colleague will listen to the audio;
> we will anonymize and transcribe the data before we share
> it with the product design team.
>
> If you feel uncomfortable with being recorded at any time we can pause
> the recording.
>
> You can cancel the interview at any time if you feel it is needed.

It rarely happened to me that someone did not agree to being recorded. If that
happens to you, you can ask if they have any specific worries—possibly you can
inform them about that specific aspect, and they might agree when they
have additional information.

> [Example from an in-house research project] “Audio recording… I’m not sure about this…”
> “Thats fine with me. Though, may I ask what worries are?” “Hmm…yeah, I don't like, you know, human
>  resources to get that data”
>
>  “I understand your concern. It is fine if you don't agree but I can
>  assure you that Human Resources is a separate section. We don't share
>  personal data and what we record today is not accessible to them. Also, all data
>  that leaves my computer or the one of my colleague is being anonymized
>  and we remove all data that points to you as person, including names,
>  workplace and so on.


If they don’t agree, just stick with writing notes.

Consider summarizing the information about the research and the use of
the participant's data in a consent form that the user signs. In this
case keep the signed form, but hand the participant a copy of the form.
Thus, the agreement is clear for both sides. See in the Appendix for an
[example of such a form](#consentForm).

After the participant has given their consent, you can start the research
session.

### Start simple

Start with some easy-to-answer questions—like: “Lets start with some simple questions about your job”. You can ask “What is your job title” and maybe follow “How do you name your Job when friends ask you what you do?”. As well, it might be interesting how experienced the person is: “How long have you been working in your current occupation?” These examples are tied to work related studies—for doing research with university students I tie the questions to their particular context and ask, for example, how long they have been studying so far.

These questions will help you to get to know some context of the participant’s work. But there is another advantage: Such questions are easy to answer. This gets the participants used to answering questions and opening up towards you. After a brief section with these easy-to-answer questions, you can transition to questions that demand more elaborate answers.

## Assure and encourage

### Affirm that you listen

You will ask questions aiming for descriptions and longer answers. So you will be listening to the participant most of the time. You probably have some ways to intuitively show that you listen—like nodding with the head or saying “yes” or “mm-mhh”. This is an important way to ensure the participant that their information is listened to and valued.

However, when giving this kind of feedback you should be careful. You could easily skew the answers by indicating that some information is better than other. If you throw in a “yes, great” combined with nodding (as if you prefer what the participant did in comparison to something else) or if you just make a rather unmotivated “mm” and frown (as if what is told does not match your hopes), the participant will get selective about their answers and focus on what you seem to like. Try to keep the reassuring sounds or gestures neutral.

> A negative example of feedback would be:
> “It was great to hear that you say you have some trouble exchanging files by mail!” (Since you may have already thought of a feature that might be helpful in that case)

The participant will try to be a nice person try to make you happy by going on about the problems with files in mails even if sending files per mail is possibly not that bad in the participant’s view. Instead of reassuring the participant using judgments and emotions, focus on the fact that you got information you that helps you:

> “That was interesting to hear –”

You could even wrap the information up—“So, you said that…”—and/or refer to an area you like further information about. It will be clear, that you care for the information and listened well—without casting some judgment on what was told to you.

### Make a friendly impression by using body language.

Probably, you would not make a bad impression anyway, but let’s go through it nevertheless: Don't give an angry or stern impression by frowning and crossing arms and legs. Don't look careless by leaning back and looking to the ceiling. During the interview, show reactions to what the participants says or does and look him/her in the eyes (at least for members of western culture). When taking notes, maintaining eye contact is not possible all the time—but keep eye contact when you can.

![not-so-good posture](images/bodyPostureBad.jpg){.portrait}

![much better posture](images/bodyPostureGood.jpg){.portrait}

<!--  TODO: could get a "expose you non-knowledge" or so (Like in spreadley)

* Show your non-knowledge
* Show that you want to know more

-->


## Don’t skew the results

<!-- TODO possibly: The framing of "skewing" assumes that there is one true answer -->

### Ask open questions

You may have noticed that the suggested questions from the previous
section are not aiming for specific, short answers. In daily life, you often want answers to be
short and precise: “Are you a graphic designer?” “No, I am a programmer” /
“How much do you like your Job? Give a mark” “B!” / “Please name your Tools –”
“I use InDesign, Photoshop and Sketch”.

If you would diagram who speaks for how long when we ask for specific
information with a “closed” range of possibilities, it would
look like this:

![short closed questions](images/talkDiagram_closed.svg)

These questions demand very specific answers from a determined
set: Yes or no, marks from A-F, a list of nouns. They would be useful if
you would want to do statistics, for analysis that allows us to give results
like “56.3% agreed strongly on Question X”. However, we want to find out
about the *why* and *how* of the participant’s work here ^[Research  concerned
with finding out about “how” and “why” using methods like interviews and
observations is also called “qualitative” research. In contrast, “quantitative research”
usually tests hypothesis (like “an orange ›buy‹ button generates more
sales that a blue one ”) and employs controlled experiments and statistics. In this book,
we learn about qualitative methods].

Imagine, in contrast to the research session outlined above (short
answers, short questions) a day-to-day situation, in which you get to
know about somebody else’s experiences: A conversation with a friend. In
such an exchange you will tell each other about your experiences, what you
felt, why you did this and that etc. In a diagram it would look like
this:

![giving longer answers, equal share](images/talkDiagram_friend.svg)

In contrast to a conversation, our main goal is to collect data; we
don’t want to tell about our Job as a user researcher, but
hear answers from the participant. Thus asking questions and
getting answers in a user needs research session look like this:

![participant gives long answers, researcher asks short, open questions](images/talkDiagram_open.svg)


The questions we want to ask should encourage answers which describe
experiences and give some insight into the “why” and “how” of the users
activities and motivations. This type of question is called “open
question” since these questions don’t have a determined (“closed”) set of answers.


> Open questions would be: *“Describe how you started your work today”*
or *“Why did you copy that page?”*

Using such open questions encourage telling longer, story-like
answers. These answers will even contain information you did *not expect*
to get.

> A participant is describing me the printing process: *“…then I look up
 which color specification the print shop needs…”*
>
>That is a new step in the workflow I did not expect (Naively, I thought that you just send
the document to the print shop, like you would when you print it on your desktop printer –
have a file, print it).
>
> Thus, I discovered a step in the workflow and a potential field of work (taking care of color spaces and profiles), of which I did not know that it even exists!

The information you get will not be abstract as in answers like “good”
or “I dislike it”, but tied to a situation. This is preferable, because a
future product will be used in real situations and not in an abstract
space of thought.

> “I like it when the feedback [to the design] comes quickly. No annoying
waiting… it always makes me nervous. Do they [the client] like it or
do I need to throw out work?”
>
>—this tells us more about the situation
than a client’s feedback being just described as “I feel good”.

If you look back to the questions already mentioned, they will share some
characteristics.

> Here are some possible questions
>
> -   Can you describe the worst experience in your day so far?
> -   Can you tell me how you create a layout?
> -   Can you tell me what makes a client “difficult”
> -   Can you describe how do you get new ideas?


All these questions start with “…can you describe” or “…can you tell me”, which
encourages a longer answer (since “describing” or “telling” demands more than one word).
In addition, all sentences contain a *Why-*, *What-* or *How-*. These
question words, again, suggest an elaborate answer.

Thus, a template for such questions would look like *“Please tell me [how/why/what] +
[researcher’s interest]”*

Contrast this with questions like

> You: “Is this a good design?”
>
> Participant: “yes!”

“Is…” -questions will be answered with “yes” or “no”—but we don't get to know *why* the participant approves or disapproves. In addition, “Is…”-Questions are a subtle form or influence ^[Also called a “leading question”] : In case of doubt, it is  likely that are participant just agrees to the suggestion you give by asking “Is…”

Sometimes,  “Is”-Questions will  come in a disguised
form—as an addition, which is made to an open question:

> You: “Can you tell me how you solve this problem? *…Do you do it by just
 calling the client and resolving the issue?*”
>
> Participant: “Yes, I do”
>
> The first part was fine, but the “Do you…”-addition turned it into a closed question.

Avoiding closed questions is actually harder than one thinks. We intuitively try
to make answering easier with such additions like “Do you…”.

When you create your questions, check if they demand some predetermined
outcomes—if they do, they are closed questions. In this case reformulate the questions in a way
that allows and “open”, non-restricted, story-like answers.

### Be aware of your influence

<!-- Note. This repeats some info similar to the one in "affirm that you listen". I don't know if that is bad, so I keep it for now -->

A very obvious problem is influencing the participant. One way to minimize this would be
making all research sessions alike—just like you would do when using a
standardized questionnaire. But by doing this, you would loose the very strengths of the methods
described here: Being able to find out about new and unexpected things, reacting to them
and gaining  understanding of the “how” and “why” by reacting on the situation.

Each participant and their context is different and you can accommodate this by
adjusting the research session to the context and the activities of the participant.
This would not be possible when asking the same questions each time.

So you neither can’t nor should take yourself out of the research session—you will *always* have some sort of effect on the participant when you do the research.

What you should avoid, though, is influencing the participant by
“suggesting” favorable answers or actions. Some sorts of this type of influence are obvious,
others are not.

> “This is good, isn’t it?!”

Is a very obvious influence, since it blatantly states what you
think the answer should be: A “yes”.

There are less obvious influences as well:

> “Would you like a better version of this?”

In this example, a positive word (“better”) and a suggestion go together. Who would
not like an improvement?! A “yes” is guaranteed—as well as a meaningless
finding which would be “people want improvements”.

Aside from your questions, you could influence the user with your
feedback since it might suggest that there are “good” and “bad” answers.
For example, it may be tempting to correct users and show the “right
way” of doing something:

> If you know, that there is a “change color”-function in the application
and the user says: “Well; I am annoyed by that application—I'd like
to change the colors but that is impossible!” It may be tempting to
say: “No, you can change it!”

Remember, that you want to find out what your participant does and why. To
correct the participant is not very useful. If the participant would clearly benefit from knowing some
technical detail, just give the crucial information after the session. But for now, use  the possibility to further explore the topic without correcting the user.

> You can just ask “what's the reason for you doing it this way”, or,
if talking about the function itself is really  important to you, you can
ask “How did you expect to do the color change if there would be such a function?”

You may also be surprised or even annoyed by steps or actions
in a workflow of the user which seem outright superfluous.

> “When I write a text I write a draft and then send it to my colleague
via mail as an attached .doc file. My colleague comments on it and
returns the mail to me”
>
> You may think that this is rather inefficient.
You may be tempted to say “Why don't you paste the text in the mail
and comment directly? Or write it live on Etherpad? This would be far
quicker!”

Remember that nobody does inefficient things by purpose. Assume that the
user has a reason. Try to find out what this reason may be.

> Again you could ask: “what's the reason for you doing it this way”
– and remember to ask follow-up questions to further explore
the issue. In the example of the attached file it may be the case that
the rich formatting functions of a word processor are needed or that such documents
are used for just everything in this office, so that switching to a “better”
solution would impose mental costs of switching to and operating in an unusual context.

Your influencing feedback could be non-verbal as well. Like in everyday
conversations, you may shrug or frown if you disagree with an
utterance or an action. Even if you don’t say “this is wrong”, frowning
or shaking your head may have the same results.

So: don’t be afraid to react towards the participant—reacting towards the participant is
essential in our research. But don’t suggest “good” or “bad” answers or
“good” or “bad” ways of doing things by using words, gestures or facial expressions.

### Silence feels strange but is okay

<!-- TODO check if it should be merged with probing -->

Sometimes, the participant will take time to think before answering.
Intuitively, you may want to fill the silence to help the participant
along.

> “Can you describe me what happened after you were finished with
creating the print-ready-file? [1 sec] Was it all well?” “yeah, sort
of well I think”

It is tempting to fill the silence with suggestions for the answer. But
it can turn an open question (“can you describe…?”) into a closed question
(“can you describe… was it…?”/“yes”) or prevent the participant coming up with
their answer on their own.

Try to tolerate the silence. Usually, the participant will
answer within a few seconds. If you notice silence which you want to fill, count
to 3 or 5 before probing further. When the set time is up, you can ask
about the question rather than giving suggestions, like


> What makes the question hard to answer?

Or

> Can you tell me what you are thinking about?

By asking these questions, you can help the participant to continue with
elaborating on the question you asked, even if they need some thinking to
answer it. <!-- CHECK: new section-->

<!-- TODO: new section here:




TODO: possibly move switch topics here?
-->


## Take a closer look

### Probing

You got some valuable information, but there seems to be even more interesting things you may get to know about that topic. In this case you can “probe” for further information.

 We already know one way to do this: Silence. The participant may just jump in and fill the silence with further information.

> Participant: “So I had it finished and send it away to the client and then almost nothing… ”
> [Pause, Researcher nods]
> Participant: “This is difficult, then. I mean, I got a brief mail that they got the design, but […]”

If leaving a pause does not make sense, you can achieve a similar outcome by repeating the most recent statement or words the participant has said.

> Participant: “So I had it finished and send it away to the client and then almost nothing… ”
> Researcher: “almost nothing?”

This this way, you can help participants to carry on without actually adding any information yourself.

> Researcher: “almost nothing?”
> Participant: “Yes, there was a brief mail that they got the design but I was unsure if that person actually gave it to the people who can decide something. That waiting just sucks.”

If you would like to know more about something particular, you can also ask directly:

> Researcher: Can you tell me what you do in such a ›waiting‹ situation?

Asking directly can be particularly useful if the participant gave a rather vague answer:

> Participant: Well, I try to get some more information and try to find out where it got stuck
> Researcher: Could you describe me how you would do that?

When you gather your data by observing or drawing diagrams with the participant, direct questions are very useful to explore the work:

> Researcher: “I saw there was a warning in this pop-up-window. You wanted to avoid these warnings before—why would you now print the document despite of it?

Or, in the case of drawing:

> This graph seems to indicate you were in quite a good mood here. Could you explain me a bit why you seem to be less happy here [Points]?

By using these probing methods you can get additional information and show the participant that you are carefully listening and observing.

### Check your understanding

You can refer back to answers to check your grasp of what the participant talked about. In this case, even closed (yes/no) questions are OK.

> “I saw you choose the color from that palette down there—is this the same palette you choose the background color from?” “No, it is not—the palette I am using here is…”

There are several advantages of checking:

* Avoid confusions and misinterpreted research due to misunderstandings
* Show that you care for the participant’s expertise.
* Encourage participants to continue and tell you more.

For checking, you need always to refer to something that you want to check. You often need to describe it to the participant:

> [Researcher] “So: If I want to print something first I need to ask for their color profile, when I have this, I load it in InDesign, choose the profile in the pdf dialog and then export it?” [Participant] “Yes. I usually to a test afterwards by opening the pdf in addition”

For this, you and the participant need to remember much at the same time. If possible, you can aid your memory by pointing to a device or part of a drawing or just demonstrating something. Don’t only rely on talking.

<!-- TODO: Add image -->


> Can you tell me more about the function behind this button?

OR

> Here [Points to diagram] your motivation seemed to change quite quickly—can you tell me more about this?

![Researcher points to a part of the diagram](images/diagram_researcherPoints.jpg)

By checking your interpretations of the participants descriptions and activities, you can avoid misunderstandings and gain additional insights.

<!-- TODO: Ask for a demonstration and examples -->

### Ask for examples

Seeing an actual example avoids misunderstandings and gives rich opportunities for further insights: If possible, ask for an example, when participants mention activities or tools they use.

> Participant: …so I would use the thing here.
> Researcher: The thing?
> Participant: Yes, it is a little icon on my desktop that does help me, when things go wrong!
> Researcher: Can you show me how you use it?

This avoids misunderstandings. The “thing” could be a script that fixes a setting. Or something else. We don't know, and it is easier for researcher and participant to look at it together.

## Steer the course of research

<!-- TODO: Integrate into modes of data gathering and kinds of questions? -->

### Switch topics

Over the course of your research you will cover different topics. Some may be set beforehand because you think they ought to be covered; other, new topics will reveal itself during the session.

There are several reasons to actively switch topics:

* There is (seemingly) nothing more to be found out.
* You covered enough and need to switch to another topic before time runs out (In this case, plan in more time in the future)
* The participant is focusing on a topic that is not in the focus of your research.

To switch topics, you can voice your interest in the next topic:

> Could you tell me more about agreeing on a payment with the client?

If possible, you can end the block by rephrasing what you learned before moving to the next topic.

> “Let me briefly summarize: […]. Next, could you tell me more about agreeing on a payment with the client?

Referring to the previous topic can also help to give a sense of closure for the previous topic.

> Thanks for telling me about specifying the task together with the client. What is also of interest for me: How do you agree on payment for your design work?

This can be particularly useful if a participant is carried away by a topic that is not relevant for you.

> So, knowing about lead typesetting is important for design work… There is another topic that might seem very different, but it is important to me: Could you tell me more about agreeing on a payment with the client?

To make the topic changes less abrupt, and to show that you listened carefully, you can refer to a topic which was mentioned but not explored yet:

> In the diagram, you drew a blob for “printery”—can you tell be a bit more about how do you get the design printed?

or:

> You mentioned that the application needs to have the correct file format when you collaborate with someone. Could you tell me a bit more about your collaboration process?

By altering the topic you can cover the issues you need to know about and, if needed, bring your research back on course. But do it considerate—each topic needs time to unfold.

### Switch methods

<!-- MAYBE: add context to the examples like "switching from… to… while saying on topic" -->

Every method has its strength and weaknesses. So it makes sense to transition between methods in your research

By using different methods on the same topic, you can gain new perspectives on it.

> Here a possible switch from interview to observation:
> “You told me your general process of setting up a document for your designs. Could you show me how you do this for your current project?”
>
> In this case, you already have a description of the activity. By observing the process, you can gain a less general, more specific and contextual view on it.

The methods you use on the same topic can be intertwined: During the demonstration of the activity, the participant may add to their description.

> The participant explains while demonstrating: “So, I write a brief sticky note with what I think is important. I actually do this fairly often. I think I did not mention it before!”

Often, methods are switched together with the topic. You may have heard about motivations of the participant and now would like to explore an activity:

> You said that collecting inspiration on the web is fun for you. Could you show me how you do that? Just do what you would do if I would not be here—and if possible, tell me what you are thinking while doing it.

Or you might want to talk in depth about the project structure that a participant just sketched in a diagram:

> In this diagram you wrote that you have some conflicts with the client. Could you tell me a bit more about this?

Again, the methods can be intertwined:

> You said that the client is often unclear in what he wants and says things like “it should pop more”. I write that here in the diagram, so I can remember it.

Using different methods and switching between them may seem like additional work. However, it can ease your work and, at the same time, improve its outcomes—just like choosing the right tools in manual crafts.

## Recording data

### Notes
![making notes on a clipboard](images/notizenKlemmbrett.jpg){.portrait}

<!-- SECTION: INTRO -->

While you observe or listen to the participant you will take brief notes. This is rather similar like taking notes in school or university: You go for the gist of what was said but you don't write down the exact words (Except in the case you find a particular expression itself important). One utterance or observation concerning one topic goes in one line, bullet-point style.

\
<!-- SECTION: TECHNIQUE -->

When you look down at your notes and think about what to write, listening and observing don't work well. Try too keep it as unobtrusive as possible.


* If you don’t care too much about your handwriting you can write notes without much looking at the paper except for some occasional glances (the method has its limits, though)
* Because of the difficulties of balancing observing, listening and note taking, there are obvious benefits of a partner who does the research with you. One person can ask questions and guide through the research, the other person takes notes. Both observe and listen.
* <!-- audio: you can afford to skip writing down verbatim comments of the person; -->
If you record audio in parallel you can be more relaxed when writing what was *said*. However, you still need to take notes to keep what you observed. This can also be very useful when you listen to the audio later and wonder what was referred to when the participant refers to things as “it” and “that”—without notes it can be hard to reconstruct what the participant was talking about.

\

<!-- expect to write lots of notes. Depending on person. For 30 min 2 DINA4-->
When I take notes in research I write often about 1 A4 page each 15min., sometimes more, sometimes less. So it does not make sense to try to write everything on one sheet or even in some space left on the cheat-sheet with your questions on it.

![Example for a sheet with research notes, written ca. over 20min](images/notesheet.png)

\
<!-- SECTION: CONTENT -->
You will supplement, transcribe and analyze your notes after the data gathering. Thus you need to be able to make sense of them later. Between collecting the data and reviewing your notes, the *context* is easily forgotten: If you just write ”empty page” it may make totally sense at the moment you write that, seeing what is happening and  knowing what happened before and after. But without that implicit knowledge “empty page” does not make much sense.

> Rather than “creates empty page” write
> “creates empty pages to organize drafts”
>
> Instead of “changes objects” write
> “Changes object size to match grid”


### Audio

Unlike making notes on paper, making an audio recording is a rather passive process except
 for pressing the record button.

I recommend using audio recordings—it is a useful supplement to your notes. It will record
the audio during the research session so that you can listen to what was said hereafter.
Note that it is not a perfect capture of all that happened: It records only sound, so if the
participant points to the screen and refers to “this”, the recording is not much of help.

### Photos

Making photos is rather easy and can capture lots of information. For example, you can
photograph the participant's desk to aid your memory. Later, you can go back and see
what was on it: Paper, pens, computer; were there tidy looking stacks and containers
for all the utensils? Or was it seemingly messy?

You can photograph the users screen if your research involves computers and gadgets.
Tech savvy users may cringe since a software based screenshot is technically superior –
but if the user does not know you to make a screenshot, a camera is a handy way to capture
the screen.

You should be able to make  photos with your camera quickly and reliably.
Thus, use a device you know and which has a good auto-mode.
The only setting that I use beyond that is the exposure compensation
in case an important part of the image totally dark or disappears in light.
Exposure compensation allows adjusting for that.

Avoid complicated set-ups or even arranging the participant and his/her tools. Arranging the participant and his/her
tools would change the data you record.

![photographing the working user](images/NutzerFotografieren.jpg)

![photographing a screen instead of using screenshots](images/ObservationDesignU4ScreenFontMix.jpg)

### Sketches
The Observations you make are, by nature, visual and concerned with processes.
Make sketches or even little storyboards to capture what you see.

It is very useful that you can choose what to draw: highlight what is important, leave out what is
irrelevant and make annotations to ease understanding the sketches later.

I mostly use my sketches the same way I use notes: Notes and sketches are made on a common
sheet of paper; one sketched observation goes in one line, if possible

![Sketches on the note sheet](images/sketchesInNotes.png)

### Diagrams

A big advantage of diagrams are that the data gathering and documentation happen at the same time. So, there is not much to add. Happy diagramming!.
